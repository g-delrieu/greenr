{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from ingredient_phrase_tagger.training import utils\n",
    "from string import punctuation\n",
    "import sklearn_crfsuite\n",
    "from nltk.tokenize import *\n",
    "import re\n",
    "import json\n",
    "from itertools import chain\n",
    "import nltk\n",
    "import pycrfsuite\n",
    "import pickle as cPickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from googletrans import Translator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = PunktSentenceTokenizer()\n",
    "\n",
    "filename = 'finalized_model.pkl'\n",
    "loaded_model = cPickle.load(open(filename, 'rb'))\n",
    "tagger = loaded_model.tagger_\n",
    "\n",
    "def get_ingredients_url(url):\n",
    "\n",
    "    page = requests.get(f'{url}')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    ingredient = ''\n",
    "\n",
    "    for a in soup.find_all('li', class_ = \"recipe-ingredients__list-item\"):\n",
    "        ingredient += a.get_text()+ '.'\n",
    "        ingredient += '\\n'\n",
    "\n",
    "    servingsize = soup.find('p', class_ = \"recipe-metadata__serving\").get_text().split(' ')[1]\n",
    "    recipe_title = soup.find('h1', class_ = 'gel-trafalgar content-title__text').get_text()\n",
    "\n",
    "    try:\n",
    "        servingsize = str(servingsize).split('-')[0]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return ingredient, servingsize, recipe_title\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [word[-1] for word in sent]\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word[:-1] for word in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [word[0] for word in sent]\n",
    "\n",
    "\n",
    "def get_sentence_features(sent):\n",
    "    \"\"\"Gets  the features of the sentence\"\"\"\n",
    "    sent_tokens = nltk.word_tokenize(utils.cleanUnicodeFractions(sent))\n",
    "\n",
    "    sent_features = []\n",
    "    for i, token in enumerate(sent_tokens):\n",
    "        token_features = [token]\n",
    "        token_features.extend(utils.getFeatures(token, i+1, sent_tokens))\n",
    "        sent_features.append(token_features)\n",
    "    return sent_features\n",
    "\n",
    "def format_ingredient_output(tagger_output, display=False):\n",
    "    \"\"\"Formats the tagger output into a more convenient dictionary\"\"\"\n",
    "    data = [{}]\n",
    "    display = [[]]\n",
    "    prevTag = None\n",
    "\n",
    "\n",
    "    for token, tag in tagger_output:\n",
    "    # turn B-NAME/123 back into \"name\"\n",
    "        tag = re.sub(r'^[BI]\\-', \"\", tag).lower()\n",
    "\n",
    "        # ---- DISPLAY ----\n",
    "        # build a structure which groups each token by its tag, so we can\n",
    "        # rebuild the original display name later.\n",
    "\n",
    "        if prevTag != tag:\n",
    "            display[-1].append((tag, [token]))\n",
    "            prevTag = tag\n",
    "        else:\n",
    "            display[-1][-1][1].append(token)\n",
    "            #               ^- token\n",
    "            #            ^---- tag\n",
    "            #        ^-------- ingredient\n",
    "\n",
    "            # ---- DATA ----\n",
    "            # build a dict grouping tokens by their tag\n",
    "\n",
    "            # initialize this attribute if this is the first token of its kind\n",
    "        if tag not in data[-1]:\n",
    "            data[-1][tag] = []\n",
    "\n",
    "        # HACK: If this token is a unit, singularize it so Scoop accepts it.\n",
    "        if tag == \"unit\":\n",
    "            token = utils.singularize(token)\n",
    "\n",
    "        data[-1][tag].append(token)\n",
    "\n",
    "    # reassemble the output into a list of dicts.\n",
    "    output = [\n",
    "        dict([(k, utils.smartJoin(tokens)) for k, tokens in ingredient.items()])\n",
    "        for ingredient in data\n",
    "        if len(ingredient)\n",
    "    ]\n",
    "\n",
    "    # Add the raw ingredient phrase\n",
    "    for i, v in enumerate(output):\n",
    "        output[i][\"input\"] = utils.smartJoin(\n",
    "            [\" \".join(tokens) for k, tokens in display[i]])\n",
    "\n",
    "    return output\n",
    "\n",
    "def parse_ingredient(sent):\n",
    "    \"\"\"ingredient parsing logic\"\"\"\n",
    "    sentence_features = get_sentence_features(sent)\n",
    "    tags = tagger.tag(sentence_features)\n",
    "    tagger_output = zip(sent2tokens(sentence_features), tags)\n",
    "    parsed_ingredient =  format_ingredient_output(tagger_output)\n",
    "    if parsed_ingredient:\n",
    "        parsed_ingredient[0]['name'] = parsed_ingredient[0].get('name','').strip('.')\n",
    "\n",
    "    return parsed_ingredient\n",
    "\n",
    "\n",
    "\n",
    "def parse_recipe_ingredients(ingredient_list):\n",
    "\n",
    "    \"\"\"Wrapper around parse_ingredient so we can call it on an ingredient list\"\"\"\n",
    "    sentences = tokenizer.tokenize(ingredient_list)\n",
    "    sentences = [sent.strip('\\n') for sent in sentences]\n",
    "    names = []\n",
    "    qtys = []\n",
    "    units = []\n",
    "    our_punctuation = '!\"#$%&\\'())*+:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "    for sent in sentences:\n",
    "        for punctuation in our_punctuation:\n",
    "        # cleaning for common issues\n",
    "            sent = sent.replace(punctuation, '')\n",
    "\n",
    "        sent = sent.replace('can', '')\n",
    "        sent = sent.replace('package', '')\n",
    "        sent = sent.replace('container', '')\n",
    "        sent = sent.replace('eggs eggs', 'eggs')\n",
    "        sent = sent.replace('⅓', '.33')\n",
    "        sent = sent.replace('½', '.5')\n",
    "        sent = sent.replace('¼', '.25')\n",
    "        sent = sent.replace('¾', '.75')\n",
    "        sent = sent.replace('tsp', 'teaspoon')\n",
    "        sent = sent.replace('tbsp', 'tablespoon')\n",
    "        sent = sent.replace('large', '')\n",
    "        sent = sent.replace('medium', '')\n",
    "        sent = sent.replace('small', '')\n",
    "        sent = sent.replace('kg', '000g')\n",
    "        sent = sent.replace('aubergine', 'eggplant')\n",
    "\n",
    "        if re.search(\"\\dg\", sent) is not None:\n",
    "            sent = sent.replace(\"g\", \"gram\", 1)\n",
    "\n",
    "\n",
    "        parsed_ingredient = parse_ingredient(sent)\n",
    "\n",
    "        print(parsed_ingredient)\n",
    "        if 'name' in parsed_ingredient[0].keys():\n",
    "\n",
    "            tmp = parsed_ingredient[0]['name']\n",
    "            useless_quantifiers = ['oz', 'fl', 'ounce']\n",
    "\n",
    "            try:\n",
    "                names.append(re.search(\"[^\\d]*$\", tmp).group(0))\n",
    "            except:\n",
    "                names.append(tmp)\n",
    "\n",
    "        else:\n",
    "            names.append(np.nan)\n",
    "\n",
    "        if 'gram' in parsed_ingredient[0]['input']:\n",
    "            units.append('gram')\n",
    "        elif 'milliliters' in parsed_ingredient[0]['input']:\n",
    "            units.append('ml')\n",
    "        elif 'unit' in parsed_ingredient[0].keys():\n",
    "            units.append(parsed_ingredient[0]['unit'])\n",
    "        #elif 'kg' or 'kilogram' in parsed_ingredient[0]['input']:\n",
    "        #   units.append('kilogram')\n",
    "        else:\n",
    "            units.append('unit')\n",
    "\n",
    "        if re.search(\"\\dg\", sent) is not None:\n",
    "            try:\n",
    "                qtys.append(re.search(\"\\d+(?=\\s*g)\", parsed_ingredient[0]['input']).group(0))\n",
    "            except:\n",
    "                pass\n",
    "        elif re.search(\"\\dkg\", sent) is not None:\n",
    "            try:\n",
    "                qtys.append(re.search(\"\\d+(?=\\s*kg)\", parsed_ingredient[0]['input']).group(0))\n",
    "            except:\n",
    "                pass\n",
    "        elif 'qty' in parsed_ingredient[0].keys():\n",
    "            qtys.append(parsed_ingredient[0]['qty'])\n",
    "        else:\n",
    "            try:\n",
    "                qtys.append(float(parsed_ingredient[0]['input'][:3]))\n",
    "            except:\n",
    "                qtys.append(np.nan)\n",
    "\n",
    "\n",
    "    final_df = pd.DataFrame(list(zip(qtys, units, names)), columns = ['qty', 'unit', 'name'])\n",
    "\n",
    "    final_df = final_df[final_df['name'].notna()]\n",
    "    final_df = final_df[final_df['unit'].notna()]\n",
    "\n",
    "    final_df.loc[final_df['unit'] == 'teaspoon', 'qty'] = 0\n",
    "    final_df.loc[final_df['unit'] == 'teaspoon', 'unit'] = 'gram'\n",
    "    final_df.loc[final_df['qty'].astype(str) == 'nan', 'qty'] = 1\n",
    "\n",
    "    return final_df, parsed_ingredient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = get_ingredients_url('https://www.bbc.co.uk/food/recipes/sweet_and_sour_slaw_07245')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_recipe_ingredients(ingredient_list):\n",
    "\n",
    "    \"\"\"Wrapper around parse_ingredient so we can call it on an ingredient list\"\"\"\n",
    "    sentences = tokenizer.tokenize(ingredient_list)\n",
    "    sentences = [sent.strip('\\n') for sent in sentences]\n",
    "    names = dict()\n",
    "    qtys = dict()\n",
    "    units = dict()\n",
    "    our_punctuation = '!\"#$%&\\'())*+:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "    for sent in sentences:\n",
    "        for punctuation in our_punctuation:\n",
    "        # cleaning for common issues\n",
    "            sent = sent.replace(punctuation, '')\n",
    "\n",
    "        sent = sent.replace('can', '')\n",
    "        sent = sent.replace('package', '')\n",
    "        sent = sent.replace('container', '')\n",
    "        sent = sent.replace('eggs eggs', 'eggs')\n",
    "        sent = sent.replace('⅓', '.33')\n",
    "        sent = sent.replace('½', '.5')\n",
    "        sent = sent.replace('¼', '.25')\n",
    "        sent = sent.replace('¾', '.75')\n",
    "        sent = sent.replace('tsp', 'teaspoon')\n",
    "        sent = sent.replace('tbsp', 'tablespoon')\n",
    "        sent = sent.replace('large', '')\n",
    "        sent = sent.replace('medium', '')\n",
    "        sent = sent.replace('small', '')\n",
    "        sent = sent.replace('kg', '000g')\n",
    "        sent = sent.replace('aubergine', 'eggplant')\n",
    "\n",
    "        if re.search(\"\\dg\", sent) is not None:\n",
    "            sent = sent.replace(\"g\", \"gram\", 1)\n",
    "\n",
    "\n",
    "        parsed_ingredient = parse_ingredient(sent)\n",
    "\n",
    "        if 'name' in parsed_ingredient[0].keys():\n",
    "\n",
    "            tmp = parsed_ingredient[0]['name']\n",
    "            useless_quantifiers = ['oz', 'fl', 'ounce']\n",
    "\n",
    "            try:\n",
    "                name = re.search(\"[^\\d]*$\", tmp).group(0)\n",
    "            except:\n",
    "                name = tmp\n",
    "\n",
    "        else:\n",
    "            name = np.nan\n",
    "\n",
    "        if 'gram' in parsed_ingredient[0]['input']:\n",
    "            units[name] = 'gram'\n",
    "        elif 'milliliters' in parsed_ingredient[0]['input']:\n",
    "            units[name] = 'ml'\n",
    "        elif 'unit' in parsed_ingredient[0].keys():\n",
    "            units[name] = parsed_ingredient[0]['unit']\n",
    "        else:\n",
    "            units[name] = 'unit'\n",
    "\n",
    "        if re.search(\"\\dg\", sent) is not None:\n",
    "            try:\n",
    "                qtys[name] = re.search(\"\\d+(?=\\s*g)\", parsed_ingredient[0]['input']).group(0)\n",
    "            except:\n",
    "                pass\n",
    "        elif 'qty' in parsed_ingredient[0].keys():\n",
    "            qtys[name] = parsed_ingredient[0]['qty']\n",
    "        else:\n",
    "            try:\n",
    "                qtys[name] = float(parsed_ingredient[0]['input'][:3])\n",
    "            except:\n",
    "                qtys[name] = np.nan\n",
    "\n",
    "    return units, qtys\n",
    "\n",
    "    #final_df = pd.DataFrame(list(zip(qtys, units, names)), columns = ['qty', 'unit', 'name'])\n",
    "\n",
    "    #final_df = final_df[final_df['name'].notna()]\n",
    "    #final_df = final_df[final_df['unit'].notna()]\n",
    "\n",
    "    #final_df.loc[final_df['unit'] == 'teaspoon', 'qty'] = 0\n",
    "    #final_df.loc[final_df['unit'] == 'teaspoon', 'unit'] = 'gram'\n",
    "    #final_df.loc[final_df['qty'].astype(str) == 'nan', 'qty'] = 1\n",
    "\n",
    "    #return final_df\n",
    "\n",
    "\n",
    "def parse_ingredient(sent):\n",
    "    \"\"\"ingredient parsing logic\"\"\"\n",
    "    sentence_features = get_sentence_features(sent)\n",
    "    tags = tagger.tag(sentence_features)\n",
    "    tagger_output = zip(sent2tokens(sentence_features), tags)\n",
    "    parsed_ingredient =  format_ingredient_output(tagger_output)\n",
    "    if parsed_ingredient:\n",
    "        parsed_ingredient[0]['name'] = parsed_ingredient[0].get('name','').strip('.')\n",
    "\n",
    "    return parsed_ingredient\n",
    "\n",
    "def get_sentence_features(sent):\n",
    "    \"\"\"Gets  the features of the sentence\"\"\"\n",
    "    sent_tokens = nltk.word_tokenize(utils.cleanUnicodeFractions(sent))\n",
    "\n",
    "    sent_features = []\n",
    "    for i, token in enumerate(sent_tokens):\n",
    "        token_features = [token]\n",
    "        token_features.extend(utils.getFeatures(token, i+1, sent_tokens))\n",
    "        sent_features.append(token_features)\n",
    "    return sent_features\n",
    "\n",
    "tokenizer = PunktSentenceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit, qty = parse_recipe_ingredients(test_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cabbage approx ', '', 'fat onions', 'red peppers', 'yellow pepper', 'orange pepper', 'red chilli', 'approx ', 'coriander ', 'pineapple juice', 'limes', 'sea salt flakes', 'sesame oil ', 'maple syrup '])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = []\n",
    "qtys = []\n",
    "names = []\n",
    "for item in unit.keys():\n",
    "    if unit.keys() != '':\n",
    "        names.append(item)\n",
    "        qtys.append(qty[item])\n",
    "        units.append(unit[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(list(zip(qtys, units, names)), columns = ['qty', 'unit', 'raw_ingredient'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    qty        unit                        name\n",
      "0   250        gram                oz chana dal\n",
      "1     1       clove                     garlic \n",
      "2     0        gram          red chilli powder \n",
      "3     0        gram                   turmeric \n",
      "4     1        unit             cinnamon stick \n",
      "5     1        unit                       onion\n",
      "6   1–2  tablespoon                       ghee \n",
      "8   1–2  tablespoon                       ghee \n",
      "9     2       clove                      garlic\n",
      "10    0        gram                cumin seeds \n",
      "11    0        gram              mustard seeds \n",
      "12    2        unit               red chillies \n",
      "13    1        unit                curry leaves\n",
      "14    2  tablespoon            tamarind chutney\n",
      "15  2.5        unit        in piece root ginger\n",
      "16    1     handful  coriander dill and chervil\n",
      "17    0        gram               chaat masala \n",
      "['Peas', 'Onions & Leeks', 'Chilli and pepper', 'Biscuit', 'Cinnamon', 'Onions', 'Green lentils', 'Green lentils', 'Onions & Leeks', 'Other Fruit', 'Mustard', 'Chilli and pepper', 'Citrus Fruit', 'Cane Sugar', 'Spices', 'Celery', 'Chilli and pepper']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '3–4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-609-ff034ed51330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.bbc.co.uk/food/recipes/chana_daal_with_tarka_62765'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/g-delrieu/greenr/greenr/main_calculation.py\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0men\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mdf_parsed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_ingredient'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_ingredient_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mghg_impact_sum\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservingsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_parsed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipe_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mghg_impact_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_parsed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '3–4'"
     ]
    }
   ],
   "source": [
    "a, df, b, c = calculate('https://www.bbc.co.uk/food/recipes/chana_daal_with_tarka_62765')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper_parser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredients_url(url):\n",
    "\n",
    "    page = requests.get(f'{url}')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    ingredient = ''\n",
    "\n",
    "    for a in soup.find_all('li', class_ = \"recipe-ingredients__list-item\"):\n",
    "        ingredient += a.get_text()+ '.'\n",
    "        ingredient += '\\n'\n",
    "\n",
    "    servingsize = soup.find('p', class_ = \"recipe-metadata__serving\").get_text().split(' ')[1]\n",
    "    recipe_title = soup.find('h1', class_ = 'gel-trafalgar content-title__text').get_text()\n",
    "\n",
    "    try:\n",
    "        servingsize = (float(servingsize[0])+float(servingsize[-1]))/2\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return ingredient, servingsize, recipe_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('250g/9oz chana dal, soaked overnight or for at least 2 hours.\\n1 garlic clove.\\n1 tsp red chilli powder.\\n½ tsp ground turmeric.\\n1 cinnamon stick.\\n1 onion, thinly sliced.\\n1–2 tbsp ghee .\\nsalt, to taste.\\n1–2 tbsp ghee .\\n2 garlic cloves, thinly sliced.\\n1 tsp cumin seeds.\\n1 tsp mustard seeds.\\n2 long dried red chillies.\\n5–6 curry leaves (fresh if possible).\\n2 tbsp tamarind chutney (available in Asian shops).\\n2.5cm/1in piece root ginger, peeled and very thinly sliced.\\nhandful mixed fresh coriander, dill and chervil, finely chopped.\\n1 tsp chaat masala.\\n',\n",
       " 3.5,\n",
       " 'Chana dal with tarka and tamarind ')"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ingredients_url('https://www.bbc.co.uk/food/recipes/chana_daal_with_tarka_62765')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/georgesdelrieu/code/g-delrieu/greenr/greenr\n"
     ]
    }
   ],
   "source": [
    "cd greenr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homemade CRF.ipynb              matching_objects.pk\r\n",
      "MANIFEST.in                     matching_objects2.pk\r\n",
      "Makefile                        mongo_pwd.pkl\r\n",
      "OUR CRF MODEL THAT WORKS.ipynb  \u001b[1m\u001b[36mnotebooks\u001b[m\u001b[m/\r\n",
      "Procfile                        \u001b[1m\u001b[36mparsing_tools\u001b[m\u001b[m/\r\n",
      "README.md                       \u001b[1m\u001b[36mraw_data\u001b[m\u001b[m/\r\n",
      "Test mongo.ipynb                requirements.txt\r\n",
      "\u001b[1m\u001b[36mbuild\u001b[m\u001b[m/                          \u001b[1m\u001b[36mscripts\u001b[m\u001b[m/\r\n",
      "\u001b[1m\u001b[36mdata\u001b[m\u001b[m/                           setup.py\r\n",
      "\u001b[1m\u001b[36mdist\u001b[m\u001b[m/                           setup.sh\r\n",
      "error.gif                       style.css\r\n",
      "finalized_model.pkl             tagger.pkl\r\n",
      "\u001b[1m\u001b[36mgreenr\u001b[m\u001b[m/                         test\r\n",
      "\u001b[1m\u001b[36mgreenr.egg-info\u001b[m\u001b[m/                \u001b[1m\u001b[36mtests\u001b[m\u001b[m/\r\n",
      "loading.gif                     train_file\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
