{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_calculation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, df, b, c = calculate('https://www.bbc.co.uk/food/recipes/honeyandmarmaladegla_93186')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper_parser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = get_ingredients_url('https://www.bbc.co.uk/food/recipes/honeyandmarmaladegla_93186')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d,e,f = get_ingredients_url('https://www.bbc.co.uk/food/recipes/loaded_aubergine_burgers_44288')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR TEST\n",
    "h,i,j = get_ingredients_url('https://www.bbc.co.uk/food/recipes/great_british_31279')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_summary(summary):\n",
    "\n",
    "    # Remove punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        summary = str(summary).replace(punctuation, '')\n",
    "\n",
    "    # Lower text\n",
    "    summary = summary.lower()\n",
    "\n",
    "    # Stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    summary_tokenized = word_tokenize(summary)\n",
    "    text = [w for w in summary_tokenized if not w in stop_words]\n",
    "    summary = ' '.join(text)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = pre_process_summary(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pre_process_summary(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = pre_process_summary(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_and_score(summary_vector):\n",
    "\n",
    "    scoreseries = []\n",
    "\n",
    "    for j, _ in enumerate(category_summaries):\n",
    "\n",
    "        cosine_sum = 1 - spatial.distance.cosine(\n",
    "            summary_vector.toarray(), category_summary_vectors[j, :].toarray())\n",
    "\n",
    "        scoreseries.append(cosine_sum)\n",
    "\n",
    "    matchscore = max(scoreseries)\n",
    "    match = category_list[scoreseries.index(matchscore)]\n",
    "\n",
    "    return match, matchscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - spatial.distance.cosine(a2.toarray(), h2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('matching_objects2.pk', 'rb') as handle:\n",
    "    matching_objects_dict = cPickle.load(handle)\n",
    "    vectorizer = matching_objects_dict['vectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = vectorizer.transform([a1])\n",
    "d2 = vectorizer.transform([d1])\n",
    "h2 = vectorizer.transform([h1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - spatial.distance.cosine(d2.toarray(), h2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k,l,m = get_ingredients_url('https://www.bbc.co.uk/food/recipes/spinach_and_mushroom_31250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = pre_process_summary(k)\n",
    "k2 = vectorizer.transform([k1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - spatial.distance.cosine(d2.toarray(), k2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper_parser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_recipe_ingredients(ingredient_list):\n",
    "\n",
    "    \"\"\"Wrapper around parse_ingredient so we can call it on an ingredient list\"\"\"\n",
    "    sentences = tokenizer.tokenize(ingredient_list)\n",
    "    sentences = [sent.strip('\\n') for sent in sentences]\n",
    "    names = []\n",
    "    qtys = {}\n",
    "    units = {}\n",
    "    our_punctuation = '!\"#$%&\\'())*+:;<=>?@[\\\\]^_`{|}~'\n",
    "    our_units = ['gram', 'milliliters', 'thigh', 'wing', 'breast']\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        for punctuation in our_punctuation:\n",
    "        # cleaning for common issues\n",
    "            sentences[i] = sentences[i].replace(punctuation, '')\n",
    "\n",
    "        sentences[i] = sentences[i].replace('can', '')\n",
    "        sentences[i] = sentences[i].replace('package', '')\n",
    "        sentences[i] = sentences[i].replace('container', '')\n",
    "        sentences[i] = sentences[i].replace('eggs eggs', 'eggs')\n",
    "        sentences[i] = sentences[i].replace('⅓', '.33')\n",
    "        sentences[i] = sentences[i].replace('½', '.5')\n",
    "        sentences[i] = sentences[i].replace('¼', '.25')\n",
    "        sentences[i] = sentences[i].replace('¾', '.75')\n",
    "        sentences[i] = sentences[i].replace('tsp', 'teaspoon')\n",
    "        sentences[i] = sentences[i].replace('tbsp', 'tablespoon')\n",
    "        sentences[i] = sentences[i].replace('large', '')\n",
    "        sentences[i] = sentences[i].replace('medium', '')\n",
    "        sentences[i] = sentences[i].replace('small', '')\n",
    "        sentences[i] = sentences[i].replace('kg', '000g')\n",
    "        sentences[i] = sentences[i].replace('aubergine', 'eggplant')\n",
    "        sentences[i] = sentences[i].replace('free-range', '')\n",
    "\n",
    "        if re.search(\"\\dg\", sentences[i]) is not None:\n",
    "            sentences[i] = sentences[i].replace(\"g\", \"gram\", 1)\n",
    "\n",
    "\n",
    "        parsed_ingredient = parse_ingredient(sentences[i])\n",
    "        \n",
    "        ## filling names\n",
    "        if 'name' in parsed_ingredient[0].keys():\n",
    "\n",
    "            tmp = parsed_ingredient[0]['name']\n",
    "            useless_quantifiers = ['oz', 'fl', 'ounce']\n",
    "\n",
    "            try:\n",
    "                names = re.search(\"[^\\d]*$\", tmp).group(0)\n",
    "            except:\n",
    "                names = tmp\n",
    "\n",
    "        else:\n",
    "            names = np.nan\n",
    "            \n",
    "        ##filling units\n",
    "        #import pdb; pdb.set_trace()\n",
    "        for unit in our_units:\n",
    "            if unit in parsed_ingredient[0]['input']:\n",
    "                units[names] = unit\n",
    "            elif 'unit' in parsed_ingredient[0].keys():\n",
    "                units[names] = parsed_ingredient[0]['unit']\n",
    "        try: \n",
    "            units[names]\n",
    "        except:\n",
    "            units[names] = 'unit'\n",
    "\n",
    "        ##filling quantities\n",
    "        if re.search(\"\\dg\", sentences[i]) is not None:\n",
    "            try:\n",
    "                qtys[names] = re.search(\"\\d+(?=\\s*g)\", parsed_ingredient[0]['input']).group(0)\n",
    "            except:\n",
    "                pass\n",
    "        elif re.search(\"\\dkg\", sentences[i]) is not None:\n",
    "            try:\n",
    "                qtys[names] = re.search(\"\\d+(?=\\s*kg)\", parsed_ingredient[0]['input']).group(0)\n",
    "            except:\n",
    "                pass\n",
    "        elif 'qty' in parsed_ingredient[0].keys():\n",
    "            qtys[names] = parsed_ingredient[0]['qty']\n",
    "        else:\n",
    "            try:\n",
    "                qtys[names] = float(parsed_ingredient[0]['input'][:3])\n",
    "            except:\n",
    "                qtys[names] = np.nan\n",
    "    \n",
    "    \n",
    "    ## collating all elements together\n",
    "    names_list = []\n",
    "    units_list = []\n",
    "    qtys_list = []\n",
    "    for key in units.keys():\n",
    "        names_list.append(key)\n",
    "        qtys_list.append(qtys[key])\n",
    "        units_list.append(units[key])\n",
    "        \n",
    "    final_df = pd.DataFrame(list(zip(qtys_list, units_list, names_list)), columns = ['qty', 'unit', 'name'])\n",
    "\n",
    "    final_df = final_df[final_df['name'] != '']\n",
    "    final_df = final_df[final_df['name'].notna()]\n",
    "    final_df = final_df[final_df['unit'].notna()]\n",
    "\n",
    "    final_df.loc[final_df['unit'] == 'teaspoon', 'qty'] = 0\n",
    "    final_df.loc[final_df['unit'] == 'teaspoon', 'unit'] = 'gram'\n",
    "    final_df.loc[final_df['qty'].astype(str) == 'nan', 'qty'] = 1\n",
    "\n",
    "    final_df.reset_index()\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_list,b,c = get_ingredients_url('https://www.bbc.co.uk/food/recipes/stuffedchickenbreast_89240')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = parse_recipe_ingredients(ingredient_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = []\n",
    "units_list = []\n",
    "qtys_list = []\n",
    "for key in units.keys():\n",
    "    names_list.append(key)\n",
    "    qtys_list.append(qtys[key])\n",
    "    units_list.append(units[key])\n",
    "\n",
    "test_df = pd.DataFrame(list(zip(qtys_list, units_list, names_list)), columns = ['qty', 'unit', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Improving calculator with new units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/Final_conversion_table.csv')\n",
    "data = data.drop(['Average tablespoon (grams)', 'Source', 'Average Unit (if applicable) (grams)', 'Source.1'], axis = 1)\n",
    "data.columns = ['name','tablespoon','unit','wing','breast','drumstick','thigh','chop','fillet','ghg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from main_calculation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from matching import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('matching_objects2.pk', 'rb') as handle:\n",
    "    matching_objects_dict = cPickle.load(handle)\n",
    "    vectorizer = matching_objects_dict['vectorizer']\n",
    "    df_wiki_match_scores = matching_objects_dict['df_wiki_match_scores']\n",
    "    category_list = matching_objects_dict['category_list']\n",
    "    category_summary_vectors = matching_objects_dict[\n",
    "        'category_summary_vectors']\n",
    "    category_summaries = matching_objects_dict['category_summaries']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vectorizer.transform(category_summaries[:132])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_google_match(ingredient):\n",
    "\n",
    "    try:\n",
    "        ingredient, url, url_base = get_google_cse_result(ingredient)\n",
    "    except:\n",
    "        return 'nomatch', 0\n",
    "\n",
    "    pageid = get_pageid_from_base(url_base)\n",
    "\n",
    "    pagesummary = get_summary_from_id(pageid)\n",
    "\n",
    "    processed_summary = pre_process_summary(pagesummary)\n",
    "\n",
    "    summary_vector = vectorizer.transform([processed_summary])\n",
    "    \n",
    "    return summary_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_google_match('ham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_match_and_score(summary_vector):\n",
    "    category_summary_vectors = vectorizer.transform(category_summaries)\n",
    "    scoreseries = []\n",
    "\n",
    "    for j, _ in enumerate(category_summaries):\n",
    "        cosine_sum = 1 - spatial.distance.cosine(\n",
    "            summary_vector.toarray(), category_summary_vectors[j, :].toarray())\n",
    "\n",
    "        scoreseries.append(cosine_sum)\n",
    "\n",
    "    matchscore = max(scoreseries)\n",
    "    match = category_list[scoreseries.index(matchscore)]\n",
    "\n",
    "    return match, matchscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "category_summary_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_match_and_score(get_google_match('ham'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_match_and_score(get_google_match('ham'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## visualizer for two data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import os\n",
    "\n",
    "# Establishing DB connection\n",
    "mongo_key = os.environ.get('DB_PASSWORD')\n",
    "\n",
    "myclient = pymongo.MongoClient(f\"mongodb+srv://gdelrieu:{mongo_key.strip()}@cluster0.jceas.mongodb.net/test?retryWrites=true&w=majority\")\n",
    "mydb = myclient[\"greenr\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def finding_better_recipe(out):\n",
    "    mycol = mydb['recorded_recipes']\n",
    "    current_impact = out[0]\n",
    "    match = mycol.find_one({\"impact\":{'$lt':current_impact}})\n",
    "\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from main_calculation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out = calculate(\"https://www.bbc.co.uk/food/recipes/stickyjerkwingswiths_91690\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4,\n",
       "     qty        unit                    name           category    impact  \\\n",
       " 0     4        unit           spring onions     Onions & Leeks  0.272000   \n",
       " 1     1        unit    Scotch bonnet chilli  Chilli and pepper  0.336000   \n",
       " 2     1        unit    in piece root ginger             Spices  0.000000   \n",
       " 3     2  tablespoon           thyme leaves           Brassicas  0.000000   \n",
       " 4   100        unit    fl oz cider vinegar        Wine vinegar  0.000000   \n",
       " 5     3  tablespoon            clear honey          Cane Sugar  0.120000   \n",
       " 6     0        gram               allspice   Chilli and pepper  0.000000   \n",
       " 7     0        gram               cinnamon            Cinnamon  0.000000   \n",
       " 8     2  tablespoon              olive oil           Olive Oil  0.142800   \n",
       " 9     1        unit  salt and black pepper   Chilli and pepper  0.336000   \n",
       " 10   12        wing          chicken wings        Poultry Meat  8.100000   \n",
       " 12    2  tablespoon            brown sugar          Cane Sugar  0.080000   \n",
       " 13    2        unit                 oranges             Orange  0.073101   \n",
       " \n",
       "                   raw_ingredient  \n",
       " 0   0              spring onions  \n",
       " 1   1       Scotch bonnet chilli  \n",
       " 2   2       in piece root ginger  \n",
       " 3   3              thyme leaves   \n",
       " 4   4       fl oz cider vinegar   \n",
       " 5   5               clear honey   \n",
       " 6   6                  allspice   \n",
       " 7   7                  cinnamon   \n",
       " 8   8                 olive oil   \n",
       " 9   9     salt and black pepper   \n",
       " 10  10            chicken wings   \n",
       " 12  12              brown sugar   \n",
       " 13  13                   oranges  ,\n",
       " '4',\n",
       " 'Sticky jerk chicken wings',\n",
       " 'https://www.bbc.co.uk/food/recipes/stickyjerkwingswiths_91690',\n",
       " True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rec = finding_better_recipe(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from textwrap import wrap\n",
    "\n",
    "from pywaffle import Waffle\n",
    "import altair as alt\n",
    "\n",
    "def waffleplot(out, rec, en = True):\n",
    "\n",
    "    df_parsed = out[1]\n",
    "    servingsize = out[2]\n",
    "    recipe_title = out[3]\n",
    "    url = out[4]\n",
    "\n",
    "    df_parsed = df_parsed.sort_values('impact')\n",
    "    df_parsed = df_parsed.rename(columns={\"name\": \"Ingredients\"})\n",
    "    df_parsed['Ingredients'] = [item.replace('oz', '').strip()[0].upper()+item.replace('oz', '').strip()[1:] for item in df_parsed['Ingredients']]\n",
    "    # Define x(dict)\n",
    "    x = df_parsed.groupby('Ingredients')['impact'].sum()\n",
    "    x = x.reset_index()\n",
    "\n",
    "    totalghg = x['impact'].sum()\n",
    "\n",
    "    # Grouping into \"Other\"\n",
    "    if (x['impact'] >= 0.243/2).sum() != x['impact'].size: # Any ingredient smaller than 2.43\n",
    "        while x[x['Ingredients'] == 'Other']['impact'].sum() < 0.243/2 or (x['impact'] >= 0.243/2).sum() != x['impact'].size:\n",
    "            x.loc[:,'Ingredients'].iat[x[x['Ingredients'] != 'Other']['impact'].idxmin()] = 'Other'    #turn smallest ingredients name to \"Other\"\n",
    "            x = x.groupby('Ingredients')['impact'].sum()\n",
    "            x.sort_values(ascending=False, inplace=True)\n",
    "            x = x.reset_index()\n",
    "\n",
    "    # Set 'Other' to bottom of list\n",
    "    m = x['Ingredients'] != 'Other'\n",
    "    x[m].append(x[~m]).reset_index(drop = True)\n",
    "    x['impact'] = x['impact']/float(servingsize)\n",
    "    total = x['impact'].sum()\n",
    "    x['CO2 per Ingredient:'] = x['Ingredients'] + ': ' + (round(x['impact']/total*100)).astype(int).astype(str) + \"%\"\n",
    "    x['source'] = recipe_title\n",
    "    x['url'] = url\n",
    "    x = x.append(pd.DataFrame([['All',rec['impact'],rec['title'] + ': 100%',rec['title'], rec['url']]], columns = x.columns)).reset_index(drop = True)\n",
    "    \n",
    "    # Turn df into dict for graph\n",
    "    data = {x['CO2 per Ingredient:'][i]: x['impact'][i] for i in range(len(x['impact']-1))}\n",
    "\n",
    "    # Define labels for legend, wrap at 25 characters  \n",
    "    labels = [\"{0} ({1}%)\".format(k, round(100 * v/sum([v for k,v in data.items()]))) for k, v in data.items()]\n",
    "    labelswrapped = [ '\\n'.join(wrap(l, 40)) for l in labels]\n",
    "    \n",
    "    print(x)\n",
    "    recipe_title = x['source'][0]\n",
    "    selection = alt.selection_multi(fields=['CO2 per Ingredient:'], bind='legend')\n",
    "    chart1 = alt.Chart(x[:-1]).mark_bar(size = 100).encode(\n",
    "    alt.Y('sum(impact)', scale=alt.Scale(domain=[0, total]), axis = None),\n",
    "    color = alt.Color('CO2 per Ingredient:', scale=alt.Scale(scheme='spectral', domain = list(x['CO2 per Ingredient:'])[:-1])),\n",
    "    order = alt.Order('impact:N', sort='descending'),\n",
    "    tooltip = \"url\",\n",
    "    href = \"url\",\n",
    "    opacity = alt.condition(selection, alt.value(1), alt.value(0.2))).add_selection(selection).properties(width = 250,\n",
    "                                                                                                          height = 250,\n",
    "                                                                                                          title = {\"text\": ['Your recipe:', x[\"source\"][0]],\n",
    "                                                                                                                   \"color\": \"white\",\n",
    "                                                                                                                   \"fontSize\": 20\n",
    "                                                                                                                    })\n",
    "    \n",
    "    \n",
    "    chart2 = alt.Chart(x.iloc[[-1]]).mark_bar(size = 100, color = \"orange\").encode(\n",
    "    alt.Y('sum(impact)', scale=alt.Scale(domain=[0, total]), axis = None),\n",
    "    color = alt.Color('CO2 per Ingredient::N', scale=alt.Scale(scheme='rainbow')),\n",
    "    tooltip = \"url\",\n",
    "    href = \"url\",\n",
    "    opacity = alt.condition(selection, alt.value(1), alt.value(0.2))).add_selection(selection).properties(width = 250,\n",
    "                                                                                 height = 250,\n",
    "                                                                                 title = {\"text\": ['A greener option:', x['source'].iloc[-1]],\n",
    "                                                                                          \"color\": \"white\",\n",
    "                                                                                          \"fontSize\": 20})\n",
    "    \n",
    "    chart = alt.hconcat(chart1, chart2).configure(background = '#466d1d', concat=alt.CompositionConfig(spacing=100)).configure_view(strokeOpacity=0).resolve_scale(\n",
    "    color='independent')\n",
    "    \n",
    "    chart = chart.configure_legend(padding=30,\n",
    "                           orient='bottom',\n",
    "                           direction = 'vertical',\n",
    "                           offset = 0,\n",
    "                           labelColor = 'white',\n",
    "                           titleColor = 'white',\n",
    "                           titleFont = \"IBM Plex Mono\",\n",
    "                           titleFontSize = 20,\n",
    "                           titleFontWeight = 'bold',\n",
    "                           titleLimit = 0,\n",
    "                           labelFontSize = 15,\n",
    "                           labelLimit= 0)\n",
    "\n",
    "\n",
    "    \n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Ingredients    impact          CO2 per Ingredient:  \\\n",
      "0          Chicken wings  2.025000           Chicken wings: 86%   \n",
      "1   Scotch bonnet chilli  0.084000     Scotch bonnet chilli: 4%   \n",
      "2  Salt and black pepper  0.084000    Salt and black pepper: 4%   \n",
      "3                  Other  0.068275                    Other: 3%   \n",
      "4          Spring onions  0.068000            Spring onions: 3%   \n",
      "5              Olive oil  0.035700                Olive oil: 2%   \n",
      "6                    All  1.300000  Tofu Thai green curry: 100%   \n",
      "\n",
      "                      source  \\\n",
      "0  Sticky jerk chicken wings   \n",
      "1  Sticky jerk chicken wings   \n",
      "2  Sticky jerk chicken wings   \n",
      "3  Sticky jerk chicken wings   \n",
      "4  Sticky jerk chicken wings   \n",
      "5  Sticky jerk chicken wings   \n",
      "6      Tofu Thai green curry   \n",
      "\n",
      "                                                 url  \n",
      "0  https://www.bbc.co.uk/food/recipes/stickyjerkw...  \n",
      "1  https://www.bbc.co.uk/food/recipes/stickyjerkw...  \n",
      "2  https://www.bbc.co.uk/food/recipes/stickyjerkw...  \n",
      "3  https://www.bbc.co.uk/food/recipes/stickyjerkw...  \n",
      "4  https://www.bbc.co.uk/food/recipes/stickyjerkw...  \n",
      "5  https://www.bbc.co.uk/food/recipes/stickyjerkw...  \n",
      "6  https://www.bbc.co.uk/food/recipes/lighter_tha...  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-dec9031c513242ac86c2222829272082\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-dec9031c513242ac86c2222829272082\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-dec9031c513242ac86c2222829272082\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300, \"strokeOpacity\": 0}, \"background\": \"#466d1d\", \"concat\": {\"spacing\": 100}, \"legend\": {\"direction\": \"vertical\", \"labelColor\": \"white\", \"labelFontSize\": 15, \"labelLimit\": 0, \"offset\": 0, \"orient\": \"bottom\", \"padding\": 30, \"titleColor\": \"white\", \"titleFont\": \"IBM Plex Mono\", \"titleFontSize\": 20, \"titleFontWeight\": \"bold\", \"titleLimit\": 0}}, \"hconcat\": [{\"data\": {\"name\": \"data-08569f15c51df2f82dbcf546801b75c4\"}, \"mark\": {\"type\": \"bar\", \"size\": 100}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"CO2 per Ingredient:\", \"scale\": {\"domain\": [\"Chicken wings: 86%\", \"Scotch bonnet chilli: 4%\", \"Salt and black pepper: 4%\", \"Other: 3%\", \"Spring onions: 3%\", \"Olive oil: 2%\"], \"scheme\": \"spectral\"}}, \"href\": {\"type\": \"nominal\", \"field\": \"url\"}, \"opacity\": {\"condition\": {\"value\": 1, \"selection\": \"selector041\"}, \"value\": 0.2}, \"order\": {\"type\": \"nominal\", \"field\": \"impact\", \"sort\": \"descending\"}, \"tooltip\": {\"type\": \"nominal\", \"field\": \"url\"}, \"y\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"axis\": null, \"field\": \"impact\", \"scale\": {\"domain\": [0, 2.3649753699520004]}}}, \"height\": 250, \"selection\": {\"selector041\": {\"type\": \"multi\", \"fields\": [\"CO2 per Ingredient:\"], \"bind\": \"legend\"}}, \"title\": {\"text\": [\"Your recipe:\", \"Sticky jerk chicken wings\"], \"color\": \"white\", \"fontSize\": 20}, \"width\": 250}, {\"data\": {\"name\": \"data-eab097cff177061b47eeb5803ac997a7\"}, \"mark\": {\"type\": \"bar\", \"color\": \"orange\", \"size\": 100}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"CO2 per Ingredient:\", \"scale\": {\"scheme\": \"rainbow\"}}, \"href\": {\"type\": \"nominal\", \"field\": \"url\"}, \"opacity\": {\"condition\": {\"value\": 1, \"selection\": \"selector041\"}, \"value\": 0.2}, \"tooltip\": {\"type\": \"nominal\", \"field\": \"url\"}, \"y\": {\"type\": \"quantitative\", \"aggregate\": \"sum\", \"axis\": null, \"field\": \"impact\", \"scale\": {\"domain\": [0, 2.3649753699520004]}}}, \"height\": 250, \"selection\": {\"selector041\": {\"type\": \"multi\", \"fields\": [\"CO2 per Ingredient:\"], \"bind\": \"legend\"}}, \"title\": {\"text\": [\"A greener option:\", \"Tofu Thai green curry\"], \"color\": \"white\", \"fontSize\": 20}, \"width\": 250}], \"resolve\": {\"scale\": {\"color\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-08569f15c51df2f82dbcf546801b75c4\": [{\"Ingredients\": \"Chicken wings\", \"impact\": 2.0250000000000004, \"CO2 per Ingredient:\": \"Chicken wings: 86%\", \"source\": \"Sticky jerk chicken wings\", \"url\": \"https://www.bbc.co.uk/food/recipes/stickyjerkwingswiths_91690\"}, {\"Ingredients\": \"Scotch bonnet chilli\", \"impact\": 0.084, \"CO2 per Ingredient:\": \"Scotch bonnet chilli: 4%\", \"source\": \"Sticky jerk chicken wings\", \"url\": \"https://www.bbc.co.uk/food/recipes/stickyjerkwingswiths_91690\"}, {\"Ingredients\": \"Salt and black pepper\", \"impact\": 0.084, \"CO2 per Ingredient:\": \"Salt and black pepper: 4%\", \"source\": \"Sticky jerk chicken wings\", \"url\": \"https://www.bbc.co.uk/food/recipes/stickyjerkwingswiths_91690\"}, {\"Ingredients\": \"Other\", \"impact\": 0.06827536995200001, \"CO2 per Ingredient:\": \"Other: 3%\", \"source\": \"Sticky jerk chicken wings\", \"url\": \"https://www.bbc.co.uk/food/recipes/stickyjerkwingswiths_91690\"}, {\"Ingredients\": \"Spring onions\", \"impact\": 0.068, \"CO2 per Ingredient:\": \"Spring onions: 3%\", \"source\": \"Sticky jerk chicken wings\", \"url\": \"https://www.bbc.co.uk/food/recipes/stickyjerkwingswiths_91690\"}, {\"Ingredients\": \"Olive oil\", \"impact\": 0.035699999999999996, \"CO2 per Ingredient:\": \"Olive oil: 2%\", \"source\": \"Sticky jerk chicken wings\", \"url\": \"https://www.bbc.co.uk/food/recipes/stickyjerkwingswiths_91690\"}], \"data-eab097cff177061b47eeb5803ac997a7\": [{\"Ingredients\": \"All\", \"impact\": 1.3, \"CO2 per Ingredient:\": \"Tofu Thai green curry: 100%\", \"source\": \"Tofu Thai green curry\", \"url\": \"https://www.bbc.co.uk/food/recipes/lighter_thai_green_67858\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.HConcatChart(...)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waffleplot(out,rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out[1]['recipe source'] = out[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5f6c7223231a16d20402a036'),\n",
       " 'impact': 1.3,\n",
       " 'title': 'Tofu Thai green curry',\n",
       " 'url': 'https://www.bbc.co.uk/food/recipes/lighter_thai_green_67858'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(out[1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_parsed = df_parsed.append(pd.DataFrame([[0,0,0,0,rec['impact'],0,rec['title']]], columns = df_parsed.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweet potato falafel with sweet potato\n",
      "hummus and flatbreads\n"
     ]
    }
   ],
   "source": [
    "from textwrap import wrap\n",
    "\n",
    "print('\\n'.join(wrap('Sweet potato falafel with sweet potato hummus and flatbreads', 40)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing unstructured text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from ingredient_phrase_tagger.training import utils\n",
    "from string import punctuation\n",
    "import sklearn_crfsuite\n",
    "from nltk.tokenize import *\n",
    "import re\n",
    "import json\n",
    "from itertools import chain\n",
    "import nltk\n",
    "import pycrfsuite\n",
    "import pickle as cPickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PunktSentenceTokenizer()\n",
    "filename = 'finalized_model.pkl'\n",
    "loaded_model = cPickle.load(open(filename, 'rb'))\n",
    "tagger = loaded_model.tagger_\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [word[-1] for word in sent]\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word[:-1] for word in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [word[0] for word in sent]\n",
    "\n",
    "def get_sentence_features(sent):\n",
    "    \"\"\"Gets  the features of the sentence\"\"\"\n",
    "    sent_tokens = nltk.word_tokenize(utils.cleanUnicodeFractions(sent))\n",
    "\n",
    "    sent_features = []\n",
    "    for i, token in enumerate(sent_tokens):\n",
    "        token_features = [token]\n",
    "        token_features.extend(utils.getFeatures(token, i+1, sent_tokens))\n",
    "        sent_features.append(token_features)\n",
    "    return sent_features\n",
    "\n",
    "def format_ingredient_output(tagger_output, display=False):\n",
    "    \"\"\"Formats the tagger output into a more convenient dictionary\"\"\"\n",
    "    data = [{}]\n",
    "    display = [[]]\n",
    "    prevTag = None\n",
    "\n",
    "\n",
    "    for token, tag in tagger_output:\n",
    "    # turn B-NAME/123 back into \"name\"\n",
    "        tag = re.sub(r'^[BI]\\-', \"\", tag).lower()\n",
    "\n",
    "        # ---- DISPLAY ----\n",
    "        # build a structure which groups each token by its tag, so we can\n",
    "        # rebuild the original display name later.\n",
    "\n",
    "        if prevTag != tag:\n",
    "            display[-1].append((tag, [token]))\n",
    "            prevTag = tag\n",
    "        else:\n",
    "            display[-1][-1][1].append(token)\n",
    "            #               ^- token\n",
    "            #            ^---- tag\n",
    "            #        ^-------- ingredient\n",
    "\n",
    "            # ---- DATA ----\n",
    "            # build a dict grouping tokens by their tag\n",
    "\n",
    "            # initialize this attribute if this is the first token of its kind\n",
    "        if tag not in data[-1]:\n",
    "            data[-1][tag] = []\n",
    "\n",
    "        # HACK: If this token is a unit, singularize it so Scoop accepts it.\n",
    "        if tag == \"unit\":\n",
    "            token = utils.singularize(token)\n",
    "\n",
    "        data[-1][tag].append(token)\n",
    "\n",
    "    # reassemble the output into a list of dicts.\n",
    "    output = [\n",
    "        dict([(k, utils.smartJoin(tokens)) for k, tokens in ingredient.items()])\n",
    "        for ingredient in data\n",
    "        if len(ingredient)\n",
    "    ]\n",
    "\n",
    "    # Add the raw ingredient phrase\n",
    "    for i, v in enumerate(output):\n",
    "        output[i][\"input\"] = utils.smartJoin(\n",
    "            [\" \".join(tokens) for k, tokens in display[i]])\n",
    "\n",
    "    return output\n",
    "\n",
    "def parse_ingredient(sent):\n",
    "    \"\"\"ingredient parsing logic\"\"\"\n",
    "    sentence_features = get_sentence_features(sent)\n",
    "    tags = tagger.tag(sentence_features)\n",
    "    tagger_output = zip(sent2tokens(sentence_features), tags)\n",
    "    parsed_ingredient =  format_ingredient_output(tagger_output)\n",
    "    if parsed_ingredient:\n",
    "        parsed_ingredient[0]['name'] = parsed_ingredient[0].get('name','').strip('.')\n",
    "\n",
    "    return parsed_ingredient\n",
    "\n",
    "def parse_recipe_ingredients(ingredient_list):\n",
    "\n",
    "    \"\"\"Wrapper around parse_ingredient so we can call it on an ingredient list\"\"\"\n",
    "    sentences = tokenizer.tokenize(ingredient_list)\n",
    "    print(sentences)\n",
    "    sentences = [sent.strip('\\n') for sent in sentences]\n",
    "    names = []\n",
    "    qtys = {}\n",
    "    units = {}\n",
    "    our_punctuation = '!\"#$%&\\'())*+:;<=>?@[\\\\]^_`{|}~'\n",
    "    our_units = ['gram', 'milliliters', 'thigh', 'wing', 'breast', 'drumstick', 'fillet']\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        for punctuation in our_punctuation:\n",
    "        # cleaning for common issues\n",
    "            sentences[i] = sentences[i].replace(punctuation, '')\n",
    "\n",
    "        sentences[i] = sentences[i].replace('can', '')\n",
    "        sentences[i] = sentences[i].replace('package', '')\n",
    "        sentences[i] = sentences[i].replace('container', '')\n",
    "        sentences[i] = sentences[i].replace('eggs eggs', 'eggs')\n",
    "        sentences[i] = sentences[i].replace('⅓', '.33')\n",
    "        sentences[i] = sentences[i].replace('½', '.5')\n",
    "        sentences[i] = sentences[i].replace('¼', '.25')\n",
    "        sentences[i] = sentences[i].replace('¾', '.75')\n",
    "        sentences[i] = sentences[i].replace('tsp', 'teaspoon')\n",
    "        sentences[i] = sentences[i].replace('tbsp', 'tablespoon')\n",
    "        sentences[i] = sentences[i].replace('large', '')\n",
    "        sentences[i] = sentences[i].replace('medium', '')\n",
    "        sentences[i] = sentences[i].replace('small', '')\n",
    "        sentences[i] = sentences[i].replace('kg', '000g')\n",
    "        sentences[i] = sentences[i].replace('aubergine', 'eggplant')\n",
    "        sentences[i] = sentences[i].replace('free-range', '')\n",
    "\n",
    "        if re.search(\"\\dg\", sentences[i]) is not None:\n",
    "            sentences[i] = sentences[i].replace(\"g\", \"gram\", 1)\n",
    "\n",
    "\n",
    "        parsed_ingredient = parse_ingredient(sentences[i])\n",
    "\n",
    "        ## filling names\n",
    "        if 'name' in parsed_ingredient[0].keys():\n",
    "\n",
    "            tmp = parsed_ingredient[0]['name']\n",
    "            useless_quantifiers = ['oz', 'fl', 'ounce']\n",
    "\n",
    "            try:\n",
    "                names = re.search(\"[^\\d]*$\", tmp).group(0)\n",
    "            except:\n",
    "                names = tmp\n",
    "\n",
    "        else:\n",
    "            names = np.nan\n",
    "\n",
    "        ##filling units\n",
    "        #import pdb; pdb.set_trace()\n",
    "        for unit in our_units:\n",
    "            if unit in parsed_ingredient[0]['input']:\n",
    "                units[names] = unit\n",
    "            elif 'unit' in parsed_ingredient[0].keys():\n",
    "                units[names] = parsed_ingredient[0]['unit']\n",
    "        try:\n",
    "            units[names]\n",
    "        except:\n",
    "            units[names] = 'unit'\n",
    "\n",
    "        ##filling quantities\n",
    "        if re.search(\"\\dg\", sentences[i]) is not None:\n",
    "            try:\n",
    "                qtys[names] = re.search(\"\\d+(?=\\s*g)\", parsed_ingredient[0]['input']).group(0)\n",
    "            except:\n",
    "                pass\n",
    "        elif re.search(\"\\dkg\", sentences[i]) is not None:\n",
    "            try:\n",
    "                qtys[names] = re.search(\"\\d+(?=\\s*kg)\", parsed_ingredient[0]['input']).group(0)\n",
    "            except:\n",
    "                pass\n",
    "        elif 'qty' in parsed_ingredient[0].keys():\n",
    "            qtys[names] = parsed_ingredient[0]['qty']\n",
    "        else:\n",
    "            try:\n",
    "                qtys[names] = float(parsed_ingredient[0]['input'][:3])\n",
    "            except:\n",
    "                qtys[names] = np.nan\n",
    "\n",
    "\n",
    "    ## collating all elements together\n",
    "    names_list = []\n",
    "    units_list = []\n",
    "    qtys_list = []\n",
    "    for key in units.keys():\n",
    "        names_list.append(key)\n",
    "        qtys_list.append(qtys[key])\n",
    "        units_list.append(units[key])\n",
    "\n",
    "    final_df = pd.DataFrame(list(zip(qtys_list, units_list, names_list)), columns = ['qty', 'unit', 'name'])\n",
    "\n",
    "    final_df = final_df[final_df['name'] != '']\n",
    "    final_df = final_df[final_df['name'].notna()]\n",
    "    final_df = final_df[final_df['unit'].notna()]\n",
    "\n",
    "    final_df.loc[final_df['unit'] == 'teaspoon', 'qty'] = 0\n",
    "    final_df.loc[final_df['unit'] == 'teaspoon', 'unit'] = 'gram'\n",
    "    final_df.loc[final_df['qty'].astype(str) == 'nan', 'qty'] = 1\n",
    "\n",
    "    final_df.reset_index()\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"2 chicken fillets \\n  2 grams of flour\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2 chicken fillets .', '2 grams of flour']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qty</th>\n",
       "      <th>unit</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>fillet</td>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gram</td>\n",
       "      <td>flour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qty    unit      name\n",
       "0   2  fillet  chicken \n",
       "1   2    gram     flour"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_recipe_ingredients(test.replace(\"\\n\", \".\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredients_url(url):\n",
    "\n",
    "    page = requests.get(f'{url}')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    ingredient = ''\n",
    "\n",
    "    for a in soup.find_all('li', class_ = \"recipe-ingredients__list-item\"):\n",
    "        ingredient += a.get_text()+ '.'\n",
    "        ingredient += '\\n'\n",
    "\n",
    "    servingsize = soup.find('p', class_ = \"recipe-metadata__serving\").get_text()\n",
    "    recipe_title = soup.find('h1', class_ = 'gel-trafalgar content-title__text').get_text()\n",
    "\n",
    "    try:\n",
    "        servingsize = re.search(\"\\d+\", servingsize).group(0)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return ingredient, servingsize, recipe_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4 wholewheat or multiseed bread rolls (each weighing about 75g/2¾oz), halved.\\n1 large aubergine, wide middle section cut into 4 slices 2cm/¾in thick .\\n1½ tbsp extra virgin olive oil.\\n½ tsp ground cumin.\\n½ tsp ground coriander.\\n1 small red pepper, deseeded and finely sliced.\\n1 small yellow pepper, deseeded and finely sliced.\\n1 red onion, finely sliced.\\n1½ tbsp red wine vinegar.\\n1 tbsp soft light brown sugar.\\n25g/1oz fresh rocket leaves or baby leaf salad.\\n1 large beef tomato, cut into four thick slices.\\ncoriander sprigs, to garnish (optional).\\n1 small ripe avocado, peeled, stoned and roughly chopped.\\n2 tsp fresh lime juice.\\n1 small garlic clove, crushed.\\nsea salt flakes and freshly ground black pepper.\\n',\n",
       " '4',\n",
       " 'Vegan aubergine burgers')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ingredients_url('http://bbc.co.uk/food/recipes/loaded_aubergine_burgers_44288')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
