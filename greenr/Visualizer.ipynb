{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_calculation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, df, b, c = calculate('https://www.bbc.co.uk/food/recipes/honeyandmarmaladegla_93186')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper_parser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = get_ingredients_url('https://www.bbc.co.uk/food/recipes/honeyandmarmaladegla_93186')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d,e,f = get_ingredients_url('https://www.bbc.co.uk/food/recipes/loaded_aubergine_burgers_44288')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR TEST\n",
    "h,i,j = get_ingredients_url('https://www.bbc.co.uk/food/recipes/great_british_31279')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_summary(summary):\n",
    "\n",
    "    # Remove punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        summary = str(summary).replace(punctuation, '')\n",
    "\n",
    "    # Lower text\n",
    "    summary = summary.lower()\n",
    "\n",
    "    # Stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    summary_tokenized = word_tokenize(summary)\n",
    "    text = [w for w in summary_tokenized if not w in stop_words]\n",
    "    summary = ' '.join(text)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = pre_process_summary(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pre_process_summary(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = pre_process_summary(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_and_score(summary_vector):\n",
    "\n",
    "    scoreseries = []\n",
    "\n",
    "    for j, _ in enumerate(category_summaries):\n",
    "\n",
    "        cosine_sum = 1 - spatial.distance.cosine(\n",
    "            summary_vector.toarray(), category_summary_vectors[j, :].toarray())\n",
    "\n",
    "        scoreseries.append(cosine_sum)\n",
    "\n",
    "    matchscore = max(scoreseries)\n",
    "    match = category_list[scoreseries.index(matchscore)]\n",
    "\n",
    "    return match, matchscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - spatial.distance.cosine(a2.toarray(), h2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('matching_objects2.pk', 'rb') as handle:\n",
    "    matching_objects_dict = cPickle.load(handle)\n",
    "    vectorizer = matching_objects_dict['vectorizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = vectorizer.transform([a1])\n",
    "d2 = vectorizer.transform([d1])\n",
    "h2 = vectorizer.transform([h1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - spatial.distance.cosine(d2.toarray(), h2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k,l,m = get_ingredients_url('https://www.bbc.co.uk/food/recipes/spinach_and_mushroom_31250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = pre_process_summary(k)\n",
    "k2 = vectorizer.transform([k1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - spatial.distance.cosine(d2.toarray(), k2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper_parser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_recipe_ingredients(ingredient_list):\n",
    "\n",
    "    \"\"\"Wrapper around parse_ingredient so we can call it on an ingredient list\"\"\"\n",
    "    sentences = tokenizer.tokenize(ingredient_list)\n",
    "    sentences = [sent.strip('\\n') for sent in sentences]\n",
    "    names = []\n",
    "    qtys = {}\n",
    "    units = {}\n",
    "    our_punctuation = '!\"#$%&\\'())*+:;<=>?@[\\\\]^_`{|}~'\n",
    "    our_units = ['gram', 'milliliters', 'thigh', 'wing', 'breast']\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        for punctuation in our_punctuation:\n",
    "        # cleaning for common issues\n",
    "            sentences[i] = sentences[i].replace(punctuation, '')\n",
    "\n",
    "        sentences[i] = sentences[i].replace('can', '')\n",
    "        sentences[i] = sentences[i].replace('package', '')\n",
    "        sentences[i] = sentences[i].replace('container', '')\n",
    "        sentences[i] = sentences[i].replace('eggs eggs', 'eggs')\n",
    "        sentences[i] = sentences[i].replace('⅓', '.33')\n",
    "        sentences[i] = sentences[i].replace('½', '.5')\n",
    "        sentences[i] = sentences[i].replace('¼', '.25')\n",
    "        sentences[i] = sentences[i].replace('¾', '.75')\n",
    "        sentences[i] = sentences[i].replace('tsp', 'teaspoon')\n",
    "        sentences[i] = sentences[i].replace('tbsp', 'tablespoon')\n",
    "        sentences[i] = sentences[i].replace('large', '')\n",
    "        sentences[i] = sentences[i].replace('medium', '')\n",
    "        sentences[i] = sentences[i].replace('small', '')\n",
    "        sentences[i] = sentences[i].replace('kg', '000g')\n",
    "        sentences[i] = sentences[i].replace('aubergine', 'eggplant')\n",
    "        sentences[i] = sentences[i].replace('free-range', '')\n",
    "\n",
    "        if re.search(\"\\dg\", sentences[i]) is not None:\n",
    "            sentences[i] = sentences[i].replace(\"g\", \"gram\", 1)\n",
    "\n",
    "\n",
    "        parsed_ingredient = parse_ingredient(sentences[i])\n",
    "        \n",
    "        ## filling names\n",
    "        if 'name' in parsed_ingredient[0].keys():\n",
    "\n",
    "            tmp = parsed_ingredient[0]['name']\n",
    "            useless_quantifiers = ['oz', 'fl', 'ounce']\n",
    "\n",
    "            try:\n",
    "                names = re.search(\"[^\\d]*$\", tmp).group(0)\n",
    "            except:\n",
    "                names = tmp\n",
    "\n",
    "        else:\n",
    "            names = np.nan\n",
    "            \n",
    "        ##filling units\n",
    "        #import pdb; pdb.set_trace()\n",
    "        for unit in our_units:\n",
    "            if unit in parsed_ingredient[0]['input']:\n",
    "                units[names] = unit\n",
    "            elif 'unit' in parsed_ingredient[0].keys():\n",
    "                units[names] = parsed_ingredient[0]['unit']\n",
    "        try: \n",
    "            units[names]\n",
    "        except:\n",
    "            units[names] = 'unit'\n",
    "\n",
    "        ##filling quantities\n",
    "        if re.search(\"\\dg\", sentences[i]) is not None:\n",
    "            try:\n",
    "                qtys[names] = re.search(\"\\d+(?=\\s*g)\", parsed_ingredient[0]['input']).group(0)\n",
    "            except:\n",
    "                pass\n",
    "        elif re.search(\"\\dkg\", sentences[i]) is not None:\n",
    "            try:\n",
    "                qtys[names] = re.search(\"\\d+(?=\\s*kg)\", parsed_ingredient[0]['input']).group(0)\n",
    "            except:\n",
    "                pass\n",
    "        elif 'qty' in parsed_ingredient[0].keys():\n",
    "            qtys[names] = parsed_ingredient[0]['qty']\n",
    "        else:\n",
    "            try:\n",
    "                qtys[names] = float(parsed_ingredient[0]['input'][:3])\n",
    "            except:\n",
    "                qtys[names] = np.nan\n",
    "    \n",
    "    \n",
    "    ## collating all elements together\n",
    "    names_list = []\n",
    "    units_list = []\n",
    "    qtys_list = []\n",
    "    for key in units.keys():\n",
    "        names_list.append(key)\n",
    "        qtys_list.append(qtys[key])\n",
    "        units_list.append(units[key])\n",
    "        \n",
    "    final_df = pd.DataFrame(list(zip(qtys_list, units_list, names_list)), columns = ['qty', 'unit', 'name'])\n",
    "\n",
    "    final_df = final_df[final_df['name'] != '']\n",
    "    final_df = final_df[final_df['name'].notna()]\n",
    "    final_df = final_df[final_df['unit'].notna()]\n",
    "\n",
    "    final_df.loc[final_df['unit'] == 'teaspoon', 'qty'] = 0\n",
    "    final_df.loc[final_df['unit'] == 'teaspoon', 'unit'] = 'gram'\n",
    "    final_df.loc[final_df['qty'].astype(str) == 'nan', 'qty'] = 1\n",
    "\n",
    "    final_df.reset_index()\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_list,b,c = get_ingredients_url('https://www.bbc.co.uk/food/recipes/stuffedchickenbreast_89240')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = parse_recipe_ingredients(ingredient_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'units' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c3fbd2e42269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0munits_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mqtys_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mnames_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mqtys_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqtys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'units' is not defined"
     ]
    }
   ],
   "source": [
    "names_list = []\n",
    "units_list = []\n",
    "qtys_list = []\n",
    "for key in units.keys():\n",
    "    names_list.append(key)\n",
    "    qtys_list.append(qtys[key])\n",
    "    units_list.append(units[key])\n",
    "\n",
    "test_df = pd.DataFrame(list(zip(qtys_list, units_list, names_list)), columns = ['qty', 'unit', 'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breast',\n",
       " 'thighs',\n",
       " 'unit',\n",
       " 'unit',\n",
       " 'unit',\n",
       " 'tablespoon',\n",
       " 'tablespoon',\n",
       " 'gram',\n",
       " 'unit',\n",
       " 'gram',\n",
       " 'unit',\n",
       " 'unit',\n",
       " 'tablespoon',\n",
       " 'gram',\n",
       " 'tablespoon']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving calculator with new units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/Final_conversion_table.csv')\n",
    "data = data.drop(['Average tablespoon (grams)', 'Source', 'Average Unit (if applicable) (grams)', 'Source.1'], axis = 1)\n",
    "data.columns = ['name','tablespoon','unit','wing','breast','drumstick','thigh','chop','fillet','ghg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tablespoon</th>\n",
       "      <th>unit</th>\n",
       "      <th>wing</th>\n",
       "      <th>breast</th>\n",
       "      <th>drumstick</th>\n",
       "      <th>thigh</th>\n",
       "      <th>chop</th>\n",
       "      <th>fillet</th>\n",
       "      <th>ghg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alcohol</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Almonds</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.4100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anise</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.7300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apples</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apricot</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Wheat &amp; Rye (Bread)</td>\n",
       "      <td>0.00981</td>\n",
       "      <td>0.053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>White bean</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Wine</td>\n",
       "      <td>0.01475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Wine vinegar</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Yogurts</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name  tablespoon   unit  wing  breast  drumstick  thigh  \\\n",
       "0                Alcohol     0.01000    NaN   NaN     NaN        NaN    NaN   \n",
       "1                Almonds     0.01000    NaN   NaN     NaN        NaN    NaN   \n",
       "2                  Anise     0.01000    NaN   NaN     NaN        NaN    NaN   \n",
       "3                 Apples         NaN  0.080   NaN     NaN        NaN    NaN   \n",
       "4                Apricot     0.01000  0.060   NaN     NaN        NaN    NaN   \n",
       "..                   ...         ...    ...   ...     ...        ...    ...   \n",
       "128  Wheat & Rye (Bread)     0.00981  0.053   NaN     NaN        NaN    NaN   \n",
       "129           White bean     0.01000    NaN   NaN     NaN        NaN    NaN   \n",
       "130                 Wine     0.01475    NaN   NaN     NaN        NaN    NaN   \n",
       "131         Wine vinegar     0.01000    NaN   NaN     NaN        NaN    NaN   \n",
       "132              Yogurts     0.01000  0.080   NaN     NaN        NaN    NaN   \n",
       "\n",
       "     chop  fillet     ghg  \n",
       "0     NaN     NaN  1.5000  \n",
       "1     NaN     NaN  4.4100  \n",
       "2     NaN     NaN  2.7300  \n",
       "3     NaN     NaN  0.4000  \n",
       "4     NaN     NaN  0.6315  \n",
       "..    ...     ...     ...  \n",
       "128   NaN     NaN  1.3000  \n",
       "129   NaN     NaN  1.7850  \n",
       "130   NaN     NaN  1.6000  \n",
       "131   NaN     NaN  4.1700  \n",
       "132   NaN     NaN  2.5240  \n",
       "\n",
       "[133 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== printing directory =======\n",
      "===== printing content directory =======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/georgesdelrieu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/georgesdelrieu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/georgesdelrieu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/georgesdelrieu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from main_calculation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    qty        unit                    name\n",
      "0     4      fillet         chicken breasts\n",
      "1     2       thigh         chicken thighs \n",
      "2     1        unit              egg white \n",
      "3   110        unit     fl oz double cream \n",
      "4     1        unit  salt and black pepper \n",
      "5     3  tablespoon                 chervil\n",
      "6     2  tablespoon              olive oil \n",
      "7    75        gram              oz butter \n",
      "8     2        unit                shallots\n",
      "9   125        gram               mushrooms\n",
      "10  110        unit             dry sherry \n",
      "11  200        unit          chicken stock \n",
      "12    2  tablespoon                 parsley\n",
      "13  400        gram                  pasta \n",
      "14    3  tablespoon                chervil \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3970,) (5000,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2caa504ecf5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.bbc.co.uk/food/recipes/stuffedchickenbreast_89240'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/g-delrieu/greenr/greenr/main_calculation.py\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_parsed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_google\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdf_parsed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/g-delrieu/greenr/greenr/matching.py\u001b[0m in \u001b[0;36mget_categories\u001b[0;34m(df_parser_output, try_google)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0mgooglematch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_google_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingredient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msimilarity_cutoff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/g-delrieu/greenr/greenr/matching.py\u001b[0m in \u001b[0;36mget_google_match\u001b[0;34m(ingredient)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0msummary_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessed_summary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatchscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_match_and_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatchscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/g-delrieu/greenr/greenr/matching.py\u001b[0m in \u001b[0;36mget_match_and_score\u001b[0;34m(summary_vector)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         cosine_sum = 1 - spatial.distance.cosine(\n\u001b[0;32m--> 169\u001b[0;31m             summary_vector.toarray(), category_summary_vectors[j, :].toarray())\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mscoreseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/mynewenv/lib/python3.7/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcosine\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# cosine distance is also referred to as 'uncentered correlation',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;31m#   or 'reflective correlation'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/mynewenv/lib/python3.7/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcorrelation\u001b[0;34m(u, v, w, centered)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mumu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvmu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0muv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m     \u001b[0muu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m     \u001b[0mvv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3970,) (5000,) "
     ]
    }
   ],
   "source": [
    "calculate('https://www.bbc.co.uk/food/recipes/stuffedchickenbreast_89240')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
