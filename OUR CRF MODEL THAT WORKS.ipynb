{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "from itertools import chain\n",
    "import nltk\n",
    "import pycrfsuite\n",
    "\n",
    "from ingredient_phrase_tagger.training import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py                  ghg_calculator.ipynb\r\n",
      "\u001b[1m\u001b[36m__pycache__\u001b[m\u001b[m/                 \u001b[1m\u001b[36mingredient_phrase_tagger\u001b[m\u001b[m/\r\n",
      "app.py                       lib.py\r\n",
      "background.png               main_calculation.py\r\n",
      "calculator.py                matching.py\r\n",
      "\u001b[1m\u001b[36mdata\u001b[m\u001b[m/                        scraper_parser.py\r\n",
      "df_recorded_similarities.pk  style.css\r\n",
      "df_wiki_similarities.pk      vectorizer.pk\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/georgesdelrieu/code/g-delrieu/git_folder/ingredient-phrase-tagger-nyt\n"
     ]
    }
   ],
   "source": [
    "cd ingredient-phrase-tagger-nyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../tests/golden/training_data.crf') as fname:\n",
    "    lines = fname.readlines()\n",
    "    items = [line.strip('\\n').split('\\t') for line in lines]\n",
    "    items = [item for item in items if len(item)==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1$1/4', 'I1', 'L20', 'NoCAP', 'NoPAREN', 'B-QTY'],\n",
       " ['cups', 'I2', 'L20', 'NoCAP', 'NoPAREN', 'B-UNIT'],\n",
       " ['cooked', 'I3', 'L20', 'NoCAP', 'NoPAREN', 'B-COMMENT'],\n",
       " ['and', 'I4', 'L20', 'NoCAP', 'NoPAREN', 'I-COMMENT'],\n",
       " ['pureed', 'I5', 'L20', 'NoCAP', 'NoPAREN', 'I-COMMENT'],\n",
       " ['fresh', 'I6', 'L20', 'NoCAP', 'NoPAREN', 'I-COMMENT'],\n",
       " ['butternut', 'I7', 'L20', 'NoCAP', 'NoPAREN', 'B-NAME'],\n",
       " ['squash', 'I8', 'L20', 'NoCAP', 'NoPAREN', 'I-NAME'],\n",
       " [',', 'I9', 'L20', 'NoCAP', 'NoPAREN', 'OTHER'],\n",
       " ['or', 'I10', 'L20', 'NoCAP', 'NoPAREN', 'I-COMMENT']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19787"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "sent = [items[0]]\n",
    "for item in items[1:]:\n",
    "    if 'I1' in item:\n",
    "        sentences.append(sent)\n",
    "        sent = [item]\n",
    "    else:\n",
    "        sent.append(item)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "random.shuffle(sentences)\n",
    "test_size = 0.1\n",
    "data_size = len(sentences)\n",
    "\n",
    "test_data = sentences[:int(test_size*data_size)]\n",
    "train_data = sentences[int(test_size*data_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'I1', 'L4', 'NoCAP', 'NoPAREN'],\n",
       " ['teaspoon', 'I2', 'L4', 'NoCAP', 'NoPAREN'],\n",
       " ['salt', 'I3', 'L4', 'NoCAP', 'NoPAREN']]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sent2labels(sent):\n",
    "    return [word[-1] for word in sent]\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word[:-1] for word in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [word[0] for word in sent]   \n",
    "\n",
    "y_train = [sent2labels(s) for s in train_data]\n",
    "X_train = [sent2features(s) for s in train_data]\n",
    "y_test = [sent2labels(s) for s in test_data]\n",
    "X_test = [sent2features(s) for s in test_data]\n",
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.43, c2=0.012,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn_crfsuite\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.43,\n",
    "    c2=0.012,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.844957884245499"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    "labels = list(crf.classes_)\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = crf.tagger_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.pkl'\n",
    "cPickle.dump(crf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.pkl'\n",
    "loaded_model = cPickle.load(open(filename, 'rb'))\n",
    "tagger = loaded_model.tagger_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x126631090>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('trained_pycrfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from ingredient_phrase_tagger.training import utils\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.tokenize import *\n",
    "\n",
    "tokenizer = PunktSentenceTokenizer()\n",
    "\n",
    "filename = 'finalized_model.pkl'\n",
    "loaded_model = cPickle.load(open(filename, 'rb'))\n",
    "tagger = loaded_model.tagger_\n",
    "\n",
    "def get_ingredients_url(url):\n",
    "\n",
    "    page = requests.get(f'{url}')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    ingredient = ''\n",
    "\n",
    "    for a in soup.find_all('li', class_ = \"recipe-ingredients__list-item\"):\n",
    "        ingredient += a.get_text()+ '.'\n",
    "        ingredient += '\\n'\n",
    "\n",
    "    return ingredient\n",
    "    \n",
    "\n",
    "def get_sentence_features(sent):\n",
    "    \"\"\"Gets  the features of the sentence\"\"\"\n",
    "    sent_tokens = nltk.word_tokenize(utils.cleanUnicodeFractions(sent))\n",
    "\n",
    "    sent_features = []\n",
    "    for i, token in enumerate(sent_tokens):\n",
    "        token_features = [token]\n",
    "        token_features.extend(utils.getFeatures(token, i+1, sent_tokens))\n",
    "        sent_features.append(token_features)\n",
    "    return sent_features\n",
    "\n",
    "def format_ingredient_output(tagger_output, display=False):\n",
    "    \"\"\"Formats the tagger output into a more convenient dictionary\"\"\"\n",
    "    data = [{}]\n",
    "    display = [[]]\n",
    "    prevTag = None\n",
    "\n",
    "\n",
    "    for token, tag in tagger_output:\n",
    "    # turn B-NAME/123 back into \"name\"\n",
    "        tag = re.sub(r'^[BI]\\-', \"\", tag).lower()\n",
    "\n",
    "        # ---- DISPLAY ----\n",
    "        # build a structure which groups each token by its tag, so we can\n",
    "        # rebuild the original display name later.\n",
    "\n",
    "        if prevTag != tag:\n",
    "            display[-1].append((tag, [token]))\n",
    "            prevTag = tag\n",
    "        else:\n",
    "            display[-1][-1][1].append(token)\n",
    "            #               ^- token\n",
    "            #            ^---- tag\n",
    "            #        ^-------- ingredient\n",
    "\n",
    "            # ---- DATA ----\n",
    "            # build a dict grouping tokens by their tag\n",
    "\n",
    "            # initialize this attribute if this is the first token of its kind\n",
    "        if tag not in data[-1]:\n",
    "            data[-1][tag] = []\n",
    "\n",
    "        # HACK: If this token is a unit, singularize it so Scoop accepts it.\n",
    "        if tag == \"unit\":\n",
    "            token = utils.singularize(token)\n",
    "\n",
    "        data[-1][tag].append(token)\n",
    "\n",
    "    # reassemble the output into a list of dicts.\n",
    "    output = [\n",
    "        dict([(k, utils.smartJoin(tokens)) for k, tokens in ingredient.items()])\n",
    "        for ingredient in data\n",
    "        if len(ingredient)\n",
    "    ]\n",
    "\n",
    "    # Add the raw ingredient phrase\n",
    "    for i, v in enumerate(output):\n",
    "        output[i][\"input\"] = utils.smartJoin(\n",
    "            [\" \".join(tokens) for k, tokens in display[i]])\n",
    "\n",
    "    return output\n",
    "\n",
    "def parse_ingredient(sent):\n",
    "    \"\"\"ingredient parsing logic\"\"\"\n",
    "    sentence_features = get_sentence_features(sent)\n",
    "    tags = tagger.tag(sentence_features)\n",
    "    tagger_output = zip(sent2tokens(sentence_features), tags)\n",
    "    parsed_ingredient =  format_ingredient_output(tagger_output)\n",
    "    if parsed_ingredient:\n",
    "        parsed_ingredient[0]['name'] = parsed_ingredient[0].get('name','').strip('.')\n",
    "        \n",
    "    return parsed_ingredient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pycrfsuite._pycrfsuite.Tagger at 0x12822e270>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_recipe_ingredients(ingredient_list):\n",
    "    #import pdb; pdb.set_trace()\n",
    "    \"\"\"Wrapper around parse_ingredient so we can call it on an ingredient list\"\"\"\n",
    "    sentences = tokenizer.tokenize(ingredient_list)\n",
    "    sentences = [sent.strip('\\n') for sent in sentences]\n",
    "    names = []\n",
    "    qtys = []\n",
    "    units = []\n",
    "    our_punctuation = '!\"#$%&\\'())*+:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "    for sent in sentences:\n",
    "        for punctuation in our_punctuation:\n",
    "        # cleaning for common issues\n",
    "            sent = sent.replace(punctuation, '')\n",
    "\n",
    "        sent = sent.replace('can', '')\n",
    "        sent = sent.replace('package', '')\n",
    "        sent = sent.replace('container', '')\n",
    "        sent = sent.replace('eggs eggs', 'eggs')\n",
    "        sent = sent.replace('⅓', '.33')\n",
    "        sent = sent.replace('½', '.5')\n",
    "        sent = sent.replace('¼', '.25')\n",
    "        sent = sent.replace('¾', '.75')\n",
    "        sent = sent.replace('tsp', 'teaspoon')\n",
    "        sent = sent.replace('tbsp', 'tablespoon')\n",
    "        \n",
    "        if re.search(\"\\dg\", sent) is not None:\n",
    "            sent = sent.replace(\"g\", \"gram\", 1)\n",
    "            \n",
    "        \n",
    "        parsed_ingredient = parse_ingredient(sent)\n",
    "        \n",
    "        #import pdb; pdb.set_trace()\n",
    "        if 'name' in parsed_ingredient[0].keys():\n",
    "\n",
    "            tmp = parsed_ingredient[0]['name']\n",
    "            useless_quantifiers = ['oz', 'fl', 'ounce']\n",
    "\n",
    "            try:\n",
    "                names.append(re.search(\"[^\\d]*$\", tmp).group(0))\n",
    "            except:\n",
    "                names.append(tmp)\n",
    "\n",
    "\n",
    "            #else:\n",
    "            #    names.append(tmp)\n",
    "        else:\n",
    "            names.append(np.nan)\n",
    "\n",
    "        if 'gram' in parsed_ingredient[0]['input']:\n",
    "            units.append('gram')\n",
    "        elif 'milliliters' in parsed_ingredient[0]['input']:\n",
    "            units.append('ml')\n",
    "        elif 'unit' in parsed_ingredient[0].keys():\n",
    "            units.append(parsed_ingredient[0]['unit'])\n",
    "        else:\n",
    "            units.append('unit')\n",
    "\n",
    "        if re.search(\"\\dg\", sent) is not None:\n",
    "            try:\n",
    "                qtys.append(re.search(\"(\\d+)((\\d+))+\", parsed_ingredient[0]['input']).group(0))\n",
    "            except:\n",
    "                pass\n",
    "        elif 'qty' in parsed_ingredient[0].keys():\n",
    "            qtys.append(parsed_ingredient[0]['qty'])\n",
    "        else:\n",
    "            try:\n",
    "                qtys.append(float(parsed_ingredient[0]['input'][:3]))\n",
    "            except:\n",
    "                qtys.append(np.nan)\n",
    "\n",
    "\n",
    "    final_df = pd.DataFrame(list(zip(qtys, units, names)), columns = ['qty', 'unit', 'name'])\n",
    "    final_df = final_df[final_df['name'].notna()]\n",
    "    final_df = final_df[final_df['unit'].notna()]\n",
    "    final_df = final_df[final_df['unit'] != 'teaspoon']\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def url_to_df(url):\n",
    "    \n",
    "    ingredient_list = get_ingredients_url(url)\n",
    "    \n",
    "    return parse_recipe_ingredients(ingredient_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qty</th>\n",
       "      <th>unit</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>520</td>\n",
       "      <td>gram</td>\n",
       "      <td>salmon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>tablespoon</td>\n",
       "      <td>butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>unit</td>\n",
       "      <td>onion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>clove</td>\n",
       "      <td>garlic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>unit</td>\n",
       "      <td>red pepper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5</td>\n",
       "      <td>unit</td>\n",
       "      <td>carrot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>tablespoon</td>\n",
       "      <td>mango chutney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>unit</td>\n",
       "      <td>lemon juice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>unit</td>\n",
       "      <td>Scotch bonnet chilli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qty        unit                  name\n",
       "0   520        gram                salmon\n",
       "5     2  tablespoon               butter \n",
       "6     1        unit                 onion\n",
       "7     4       clove                garlic\n",
       "8   0.5        unit            red pepper\n",
       "9   0.5        unit                carrot\n",
       "11    4  tablespoon        mango chutney \n",
       "12  NaN        unit          lemon juice \n",
       "13  0.5        unit  Scotch bonnet chilli"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_to_df('https://www.bbc.co.uk/food/recipes/mango_salmon_39588')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2gram ground cinnamon\n"
     ]
    }
   ],
   "source": [
    "if re.search(\"\\dg\", \"2g ground cinnamon\").group(0) is not None:\n",
    "    print(\"2g ground cinnamon\".replace(\"g\", \"gram\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ing = get_ingredients_url('https://www.bbc.co.uk/food/recipes/hummus_chickpea_burgers_94137')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import subprocess\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_ingredients_url(url):\n",
    "\n",
    "    page = requests.get(f'{url}')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    ingredient = ''\n",
    "\n",
    "    for a in soup.find_all('li', class_ = \"recipe-ingredients__list-item\"):\n",
    "        ingredient += a.get_text()+ '.'\n",
    "        ingredient += '\\n'\n",
    "\n",
    "    return ingredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ing = get_ingredients_url('https://www.bbc.co.uk/food/recipes/hummus_chickpea_burgers_94137')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '3-4 tbsp sunflower oil ', 'input': '3-4 tbsp sunflower oil .'},\n",
       " {'qty': '1',\n",
       "  'name': 'onion',\n",
       "  'other': ',',\n",
       "  'comment': 'roughly chopped .',\n",
       "  'input': '1 onion, roughly chopped .'},\n",
       " {'qty': '2',\n",
       "  'name': 'garlic',\n",
       "  'unit': 'clove',\n",
       "  'comment': ', thinly sliced .',\n",
       "  'input': '2 garlic cloves, thinly sliced .'},\n",
       " {'qty': '1', 'name': 'tsp ground cumin ', 'input': '1 tsp ground cumin .'},\n",
       " {'qty': '1',\n",
       "  'comment': 'tsp ground',\n",
       "  'name': 'coriander ',\n",
       "  'input': '1 tsp ground coriander .'},\n",
       " {'comment': '400g tin, drained and rinsed .',\n",
       "  'name': 'chickpeas',\n",
       "  'input': '400g tin chickpeas, drained and rinsed .'},\n",
       " {'name': '100g/3 1/2oz hummus ', 'input': '100g/3 1/2oz hummus .'},\n",
       " {'comment': '50g/2oz plain',\n",
       "  'name': 'flour ',\n",
       "  'input': '50g/2oz plain flour .'},\n",
       " {'qty': '1/2', 'comment': 'tsp', 'name': 'salt ', 'input': '1/2 tsp salt .'},\n",
       " {'comment': 'freshly ground',\n",
       "  'name': 'black pepper ',\n",
       "  'input': 'freshly ground black pepper .'},\n",
       " {'comment': '50g/2oz or',\n",
       "  'name': 'pine nuts cashews ',\n",
       "  'input': '50g/2oz pine nuts or cashews .'},\n",
       " {'qty': '8',\n",
       "  'name': 'pitta breads',\n",
       "  'other': ',',\n",
       "  'comment': 'warmed .',\n",
       "  'input': '8 pitta breads, warmed .'},\n",
       " {'comment': 'mixed', 'name': 'green salad ', 'input': 'mixed green salad .'},\n",
       " {'qty': '8',\n",
       "  'name': 'tbsp plain yoghurt',\n",
       "  'comment': '(optional) .',\n",
       "  'input': '8 tbsp plain yoghurt (optional) .'},\n",
       " {'qty': '8', 'name': 'tsp chilli sauce ', 'input': '8 tsp chilli sauce .'}]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_recipe_ingredients(test_ing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_params(\n",
    "{\n",
    "        'c1': 0.43,\n",
    "        'c2': 0.012,\n",
    "        'max_iterations': 100,\n",
    "        'feature.possible_transitions': True,\n",
    "        'feature.possible_states': True,\n",
    "        'linesearch': 'StrongBacktracking'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train('trained_pycrfsuite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
